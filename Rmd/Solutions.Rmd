---
title: " Exploring Solutions"
author: "Strategic RAP Champions"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: united
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(DiagrammeR)
```

## Project Conceptual Diagram


```{r workflow, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
workflow <- DiagrammeR::grViz("digraph {
  graph [layout = dot, rankdir = TB]
  
  node [shape = rectangle]        
  rec1 [label = 'Step 1. Recovery Document Table [PDF, Word, or...]']
  rec2 [label = 'Step 2. Data Frame']
  rec3 [label = 'Step 3. Data Frame to csv, excel or...']
  rec4 [label = 'Step 4. Reporting [interactive reporting web-based and customized static reporting]']
  
  rec1 -> rec2 -> rec3 -> rec4
  }",
  height = 500)
```

```{r workflow plot}
workflow
```

## Options Step 1 to Step 2

```{r workflow2, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Option1 <- DiagrammeR::grViz("digraph {
  graph [layout = dot, rankdir = TB]
  
  node [shape = rectangle]        
  rec1 [label = 'PDF and/or embedded metadata']
  rec2 [label = 'Tool']
  rec3 [label = 'Data Frame']

  rec1 -> rec2 -> rec3 
  }",
  height = 500)
```

```{r workflow plot2}
Option1
```

#### Azure Form Recognizer

- [Azure Form Recognizer](https://docs.microsoft.com/en-us/azure/applied-ai-services/form-recognizer/overview?WT.mc_id=aiml-14201-cassieb&tabs=v3-0) is a cloud-based Azure Applied AI Service that analyzes forms and documents, extracts text and data, and maps field relationships as key-value pairs: https://formrecognizer.appliedai.azure.com/studio

#### `tabulizer` R Package
- https://github.com/ropensci/tabulizer

```{r, include=FALSE}

```

#### Tabula
- https://tabula.technology/  -- software can be used to extract data manually, or folks can implement a solution programatically using python? https://www.youtube.com/watch?v=702lkQbZx50

## Demos

#### Azure Form Recognizer
- https://www.youtube.com/watch?v=rkJa6vbkMcU
- https://github.com/Azure-Samples/cognitive-services-quickstart-code/blob/master/python/FormRecognizer/rest/python-train-extract.md

#### R packages
- https://github.com/ropensci/tabulizer
- Tabulizer Package: https://www.youtube.com/watch?v=nlsWjezvsg8
- PDF Scrape and exploratory analysis code demo: https://www.business-science.io/code-tools/2019/09/23/tabulizer-pdf-scraping.html#workflow

#### Tabula
- https://www.youtube.com/watch?v=NvcTIZ2Je50 


## Pros 

- Azure Form Recognizer allows coordination with tools withing our Microsoft Suite
- Azure Form Recognizer -- Powered with Python?
- Tabula is free and open source. Tabula was created by journalists for journalists and anyone else working with data locked away in PDFs. 

## Cons 

- Azure Form Recognizer does not seem to exist in our current suite of tools? (I logged in a ticket) or maybe there is somehting we can dowlonad easily?
- Not an open source solution (0-500 pages are free per month, after that, there is a cost associated with using this tool https://azure.microsoft.com/en-ca/pricing/details/form-recognizer/)
- Tabulizer Package seems to have a lot of dependencies and bit of a convoluted process to install it (not tested yet) - may need admin privileges
- Package ‘tabulizer’ was removed from the CRAN repository.
- Tabula:


## Flags & Questions TBD 

- Are PDFs the best way to store metadata (a.k.a) tables from Recovery Documents?
  - if no, why not, and what solutions can we offer?
  - if yes, is there any guidance we could provide for the tables themselves? this potential guidance will apply for two potential scenarios:
    - Folks working in a word document that gets converted into PDF
    - Folks generating csasdown documents --> due to lack of web accessibility issues, LaTeX generated PDFs are not web accessible - thus testing using word files instead may be key. 
- Folks writing SARA documents: would they be interested in reporting key tables in the PDF as well as an additional database?
- Folks mining these documents: what is their background? a solution involving programming may require a coding background?
- In the future, would the Recovery Documents PDF/Word host the authoritative data to be mined in the future? or is there interest in exploring additional options to store metadata (a.k.a. tables)?
- When mining tables in the future from the Recovery Document PDF/Word file:
  - Do you envision mining tables directly from the Recovery Document PDF/Word file?
  - Or are you open to recommendations in the workflow to store and mine the data from somewhere else (e.g. database, excel sheets populated as part of submission)?


## Agenda Meeting 2

### User stories
  - DFO staff is tasked with mining tables from Recovery Documents PDF/Word files to organized them in a nice and clean spreadsheet. Below are potential future scenarios of what their experience could be using different approaches.
  
####  Scenario 1: Staff mines tables directly from current Recovery Document PDF/Word files

Staff finds interesting tables that ahve weird double lines, non matching lines and background white lines separating the cells.  

#### Scenario 2: Staff mines tables directly from improved Recovery Document PDF/Word files. 

These improved documents have metadata (a.k.a. tables) that is mined at the same time as the filepath when scraping the doc.

#### Scenario 3: Staff takes advantage of a new workflow to store and mine the data from somewhere else 

Mining PDF and Word files is definitively a possiility. However, we are wodnering if there may be a better approach for mining data and storing it in an authoritative place. Data could then be mined from soemthing different than a PDF/Word file... something such as database, excel sheets, which could be populated as part of a submission. 

The evaluation of any scenario must take into account the time and user experience of i) folks writing/publishing SARA documents, ii) folks mining these documents.
     
### Recommendations for input spreadsheet 
Need a bit of cleaning before interactive report pilot - happy to do cleaning with recommendations on how to keep spreadsheets as clean as possible for coding (Excel spreadsheets, CSV, Databases)
